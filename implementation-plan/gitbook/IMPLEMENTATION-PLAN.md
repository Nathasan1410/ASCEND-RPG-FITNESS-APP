# üéØ GITBOOK IMPLEMENTATION PLAN - COMMIT TO CHANGE HACKATHON

> **Hackathon:** Commit To Change: An AI Agents Hackathon
> **Theme:** Build AI that turns New Year's resolutions into real results
> **Category:** Health, Fitness & Wellness ($5,000) + Best Use of Opik ($5,000)
> **Team:** Nathanael Santoso
> **Deadline:** Mon, Feb 9, 2026, 6:59 PM (GMT+07:00)
> **Current Stage:** Final Submissions
> **Project:** ASCEND: FITNESS RPG

---

## üèÜ STRATEGIC POSITIONING

### Why ASCEND Wins in THIS Hackathon

**Our Project:** Gamified fitness app with AI-powered quest generation and Opik AI judge

**Perfect Fit for:**
1. **Health, Fitness & Wellness Track** ($5,000)
   - ‚úÖ Direct fitness application
   - ‚úÖ Mental wellness through gamification
   - ‚úÖ Recovery tracking through rest timers
   - ‚úÖ Habit formation through daily quests

2. **Best Use of Opik** ($5,000) - **CRITICAL BONUS**
   - ‚úÖ Quest generation traces
   - ‚úÖ AI judge evaluation traces
   - ‚úÖ Performance monitoring
   - ‚úÖ Error tracking
   - ‚úÖ Goal alignment showcase

**Also Competitive In:**
3. **Personal Growth & Learning** ($5,000)
   - ‚úÖ Skill progression (E ‚Üí S rank)
   - ‚úÖ Achievement system
   - ‚úÖ Class-based learning

4. **Productivity & Work Habits** ($5,000)
   - ‚úÖ Daily quest system (routine building)
   - ‚úÖ Streak tracking (habit formation)
   - ‚úÖ Time management (quest timers)

5. **Social & Community Impact** ($5,000)
   - ‚úÖ Hunter Network feed (community connection)
   - ‚úÖ Leaderboard (social proof)
   - ‚úÖ Kudos/Respect system (encouragement)

**Potential Total: $25,000** (5 categories √ó $5,000)

---

## üìä JUDGING CRITERIA ANALYSIS

### 1. Functionality (25%)
**What Judges Want:**
- Does the app actually work?
- Are core features implemented?
- Stable and responsive?

**Our Score:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- ‚úÖ Quest generation working
- ‚úÖ Quest completion tracking
- ‚úÖ XP/leveling system
- ‚úÖ Social feed functional
- ‚úÖ Mobile responsive

### 2. Real-World Relevance (25%)
**What Judges Want:**
- How practical is this to real users?
- Does it solve actual problems?
- New Year's resolution alignment?

**Our Score:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- ‚úÖ Solves: Lack of motivation in fitness
- ‚úÖ Solves: No progress tracking
- ‚úÖ Solves: No community in fitness
- ‚úÖ Aligns: "Exercise more" resolution
- ‚úÖ Aligns: "Build habits" resolution

### 3. Use of LLMs/Agents (25%)
**What Judges Want:**
- Effective LLM usage
- Agentic systems (reasoning chains, autonomy)
- Tool use

**Our Score:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)
- ‚úÖ Groq LLM for quest generation
- ‚úÖ AI judge with multi-factor evaluation
- ‚ö†Ô∏è Limited autonomous agent behavior (quest generation is triggered)
- ‚úÖ Tool use: Supabase database queries

### 4. Evaluation and Observability (25%) - **CRITICAL FOR Opik PRIZE**
**What Judges Want:**
- Ways to evaluate/monitor system behavior?
- Opik integration?
- Robust metrics?
- Goal alignment?

**Our Score:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - **MAXIMUM**
- ‚úÖ Opik traces for ALL AI interactions
- ‚úÖ Quest generation monitoring
- ‚úÖ AI judge evaluation tracking
- ‚úÖ Performance metrics (API response times)
- ‚úÖ Error tracking and debugging
- ‚úÖ Goal alignment: Improve quest quality

**This is our WINNING CATEGORY!** üèÜ

---

## üéØ GITBOOK DOCUMENTATION STRATEGY

### Target Audience: Technical Judges

**What Judges Are Looking For:**
1. Technical depth (architecture, database, AI implementation)
2. Code quality (clean, modular, type-safe)
3. Innovation (unique value proposition)
4. Opik integration quality (comprehensive traces, goal alignment)
5. Real-world applicability (solves actual problem)
6. Scalability (can this grow?)
7. Security (RLS, input validation, anti-cheat)

### GitBook Value Proposition for Hackathon

**Why GitBook > README.md for Judges:**
- ‚úÖ **Deeper technical analysis** - Shows we understand our stack
- ‚úÖ **Searchable documentation** - Judges can find specific topics quickly
- ‚úÖ **Multi-page structure** - Better organization than single README
- ‚úÖ **Code examples with syntax highlighting** - Shows clean code practices
- ‚úÖ **Diagrams and visualizations** - Architecture becomes clear
- ‚úÖ **Bonus documentation points** - Hackathons reward comprehensive documentation

**Time Trade-off:**
- README.md: 2-3 hours (quick overview)
- GitBook: 4-6 hours (comprehensive technical deep-dive)

**ROI:** 2-3 extra hours = 2-3x documentation points = **BETTER CHANCE OF WINNING**

---

## üìö GITBOOK STRUCTURE (OPTIMIZED FOR MAXIMUM POINTS)

```
gitbook/
‚îú‚îÄ‚îÄ README.md                          (Landing - 2-min pitch + demo)
‚îú‚îÄ‚îÄ 1-Getting-Started/
‚îÇ   ‚îú‚îÄ‚îÄ quick-start.md                 (Demo accounts + local setup)
‚îÇ   ‚îî‚îÄ‚îÄ installation.md                (Detailed env setup)
‚îÇ
‚îú‚îÄ‚îÄ 2-Architecture/
‚îÇ   ‚îú‚îÄ‚îÄ system-overview.md             (High-level diagram + tech stack)
‚îÇ   ‚îú‚îÄ‚îÄ frontend-architecture.md        (Next.js App Router deep-dive)
‚îÇ   ‚îú‚îÄ‚îÄ backend-architecture.md         (Supabase + RLS policies)
‚îÇ   ‚îî‚îÄ‚îÄ ai-integration.md             (Groq + Opik - **CRITICAL**)
‚îÇ
‚îú‚îÄ‚îÄ 3-Database/
‚îÇ   ‚îú‚îÄ‚îÄ schema.md                     (Complete ER diagram + tables)
‚îÇ   ‚îú‚îÄ‚îÄ relationships.md                (Foreign keys + data flow)
‚îÇ   ‚îú‚îÄ‚îÄ rls-policies.md               (Security implementation)
‚îÇ   ‚îú‚îÄ‚îÄ optimization.md                (Indexes + query optimization)
‚îÇ   ‚îî‚îÄ‚îÄ seed-data.md                  (Dummy data + migrations)
‚îÇ
‚îú‚îÄ‚îÄ 4-Features/
‚îÇ   ‚îú‚îÄ‚îÄ quest-system.md               (Quest generation flow - **CORE FEATURE**)
‚îÇ   ‚îú‚îÄ‚îÄ ai-judge.md                  (Opik implementation - **WINNING POINT**)
‚îÇ   ‚îú‚îÄ‚îÄ gamification.md               (XP, levels, ranks)
‚îÇ   ‚îú‚îÄ‚îÄ social-feed.md                (Hunter Network)
‚îÇ   ‚îú‚îÄ‚îÄ anti-cheat.md                 (Proof uploads + verification)
‚îÇ   ‚îî‚îÄ‚îÄ real-time-leaderboard.md      (Leaderboard logic)
‚îÇ
‚îú‚îÄ‚îÄ 5-Security/
‚îÇ   ‚îú‚îÄ‚îÄ authentication.md              (Supabase Auth flow)
‚îÇ   ‚îú‚îÄ‚îÄ rls-implementation.md        (Row-level security - **SHOWS TECH DEPTH**)
‚îÇ   ‚îú‚îÄ‚îÄ api-security.md               (Route protection + validation)
‚îÇ   ‚îú‚îÄ‚îÄ proof-validation.md           (File upload security)
‚îÇ   ‚îî‚îÄ‚îÄ anti-cheat-triggers.md       (Database triggers)
‚îÇ
‚îú‚îÄ‚îÄ 6-Performance/
‚îÇ   ‚îú‚îÄ‚îÄ frontend-optimization.md       (Server Components, code splitting)
‚îÇ   ‚îú‚îÄ‚îÄ backend-optimization.md        (Database indexing, caching strategy)
‚îÇ   ‚îî‚îÄ‚îÄ opik-monitoring.md          (Performance metrics via Opik - **EXTRA POINTS**)
‚îÇ
‚îú‚îÄ‚îÄ 7-AI-Implementation/
‚îÇ   ‚îú‚îÄ‚îÄ groq-quest-generation.md     (Prompt engineering, response parsing)
‚îÇ   ‚îú‚îÄ‚îÄ opik-ai-judge.md           (Judge logic, multi-factor evaluation)
‚îÇ   ‚îú‚îÄ‚îÄ prompt-engineering.md          (Quest generation templates)
‚îÇ   ‚îî‚îÄ‚îÄ trace-implementation.md      (How we use Opik SDK - **MAXIMUM POINTS**)
‚îÇ
‚îú‚îÄ‚îÄ 8-Testing/
‚îÇ   ‚îú‚îÄ‚îÄ unit-testing.md               (Jest setup, test examples)
‚îÇ   ‚îú‚îÄ‚îÄ integration-testing.md        (Playwright tests)
‚îÇ   ‚îî‚îÄ‚îÄ load-testing.md              (k6 load test strategy)
‚îÇ
‚îú‚îÄ‚îÄ 9-Deployment/
‚îÇ   ‚îú‚îÄ‚îÄ vercel-setup.md              (Frontend deployment)
‚îÇ   ‚îú‚îÄ‚îÄ supabase-setup.md            (Backend deployment)
‚îÇ   ‚îî‚îÄ‚îÄ ci-cd-pipeline.md           (GitHub Actions)
‚îÇ
‚îú‚îÄ‚îÄ 10-Code-Examples/
‚îÇ   ‚îú‚îÄ‚îÄ server-actions.md             (Complete Server Action examples)
‚îÇ   ‚îú‚îÄ‚îÄ components.md                 (Component patterns)
‚îÇ   ‚îú‚îÄ‚îÄ hooks.md                    (Custom React hooks)
‚îÇ   ‚îî‚îÄ‚îÄ utilities.md                 (Helper functions)
‚îÇ
‚îî‚îÄ‚îÄ 11-Innovation-and-Future-Roadmap.md   (Key innovations + future plans)
```

---

## üî• CRITICAL SECTIONS FOR MAXIMUM POINTS

### 1. AI Integration (7-AI-Implementation/) - **WINS "Use of LLMs/Agents" (25%)**

**Must Include:**
```markdown
## Groq Quest Generation

### Prompt Engineering Strategy

#### System Prompt Template
```typescript
const SYSTEM_PROMPT = `You are an expert fitness trainer and RPG quest designer.

Generate personalized workout quests based on:
- User's current rank (${E-D})
- Available equipment
- Fitness goals
- Time constraints

Rules:
1. Include 3-5 exercises
2. Specify sets, reps, and weights
3. Add warm-up (5 min) and cool-down (5 min)
4. Provide form tips for each exercise
5. Include XP value based on difficulty

Response Format (JSON):
{
  "title": "Quest Name",
  "description": "Epic description",
  "difficulty": "B",
  "duration_minutes": 45,
  "exercises": [
    {
      "name": "Barbell Squat",
      "sets": 4,
      "reps": 8,
      "weight": 60,
      "form_tip": "Keep chest up, drive through heels"
    }
  ],
  "xp_reward": 500,
  "warmup": {...},
  "cooldown": {...}
}
`;
```

#### Dynamic Prompt Generation
```typescript
function generateQuestPrompt(user: UserProfile) {
  return `
${SYSTEM_PROMPT}

User Context:
- Rank: ${user.rank}
- Class: ${user.class} (${user.class === 'Tank' ? 'strength' : user.class === 'Striker' ? 'speed' : 'agility'})
- Equipment: ${user.equipment.join(', ')}
- Current Level: ${user.level}
- XP: ${user.xp}
- Goals: ${user.goals.join(', ')}

Recent Quest History:
${user.recentQuests.map(q => `- ${q.title}: ${q.completionStatus}`).join('\n')}

Generate a new quest that:
1. Is slightly harder than average (for progression)
2. Uses available equipment
3. Matches class specialization
4. Takes 30-60 minutes
`;
}
```

#### Response Parsing & Validation
```typescript
interface QuestResponse {
  title: string;
  description: string;
  difficulty: 'E' | 'D' | 'C' | 'B' | 'A' | 'S';
  duration_minutes: number;
  exercises: Exercise[];
  xp_reward: number;
}

function validateQuestResponse(response: any): QuestResponse | null {
  // Schema validation with Zod
  const schema = z.object({
    title: z.string().min(5).max(100),
    description: z.string().min(20).max(500),
    difficulty: z.enum(['E', 'D', 'C', 'B', 'A', 'S']),
    duration_minutes: z.number().min(15).max(120),
    exercises: z.array(z.object({
      name: z.string().min(3),
      sets: z.number().min(1).max(10),
      reps: z.number().min(1).max(50),
      weight: z.number().min(0).max(500),
    })).min(3).max(5),
    xp_reward: z.number().min(50).max(2000),
  });

  try {
    return schema.parse(response);
  } catch (error) {
    opik.trace('quest_validation_error', {
      error: error.message,
      rawResponse: response,
      timestamp: new Date().toISOString(),
    });
    return null;
  }
}
```

#### Fallback Strategy
```typescript
async function generateQuestWithFallback(user: UserProfile): Promise<Quest> {
  try {
    // Try AI generation
    const response = await groq.chat.completions.create({
      messages: [{ role: 'system', content: generateQuestPrompt(user) }],
      model: 'llama-3.3-70b-versatile',
      temperature: 0.7,
      max_tokens: 1000,
    });

    const quest = validateQuestResponse(JSON.parse(response.choices[0].message.content));

    // Trace successful generation
    opik.trace('quest_generation', {
      userId: user.id,
      userRank: user.rank,
      userClass: user.class,
      questDifficulty: quest.difficulty,
      exerciseCount: quest.exercises.length,
      duration: quest.duration_minutes,
      xpReward: quest.xp_reward,
      success: true,
    });

    return quest;

  } catch (aiError) {
    // Fallback to template
    opik.trace('quest_generation_fallback', {
      error: aiError.message,
      reason: 'AI generation failed',
      fallback: 'template_quest',
      userId: user.id,
    });

    return getDefaultQuestTemplate(user.rank, user.equipment);
  }
}
```

## Opik AI Judge

### Judge Logic (Multi-Factor Evaluation)

#### Evaluation Algorithm
```typescript
interface JudgeInput {
  quest: Quest;
  completion: QuestCompletion;
  proofMedia?: ProofMedia;
  userHistory: UserProfile[];
}

interface JudgeOutput {
  xp_multiplier: number;      // 0.8x - 1.5x
  feedback: string;           // Personalized feedback
  suggested_improvements: string[];
  form_score: number;         // 0.0 - 1.0 (percentage)
  effort_score: number;        // 0.0 - 1.0 (percentage)
  consistency_score: number;    // 0.0 - 1.0 (percentage)
  overall_score: number;        // Weighted average
}

async function evaluateQuestCompletion(input: JudgeInput): Promise<JudgeOutput> {
  // Factor 1: Form Evaluation (from proof)
  const formScore = await evaluateForm(input.proofMedia);
  
  // Factor 2: Effort Level (completion time vs expected)
  const effortScore = evaluateEffort(
    input.completion.duration_minutes,
    input.quest.duration_minutes
  );
  
  // Factor 3: Consistency (vs previous quests)
  const consistencyScore = evaluateConsistency(
    input.userHistory,
    input.completion
  );
  
  // Weighted average
  const overallScore = (
    (formScore * 0.4) +      // Form is 40% weight
    (effortScore * 0.3) +     // Effort is 30% weight
    (consistencyScore * 0.3)     // Consistency is 30% weight
  );
  
  // Calculate XP multiplier
  let xpMultiplier = 1.0;
  if (overallScore >= 0.9) xpMultiplier = 1.5;  // Excellent
  else if (overallScore >= 0.8) xpMultiplier = 1.3;  // Great
  else if (overallScore >= 0.7) xpMultiplier = 1.1;  // Good
  else if (overallScore >= 0.6) xpMultiplier = 1.0;  // Average
  else if (overallScore >= 0.5) xpMultiplier = 0.9;  // Below average
  else xpMultiplier = 0.8;  // Poor
  
  // Generate feedback
  const feedback = generateFeedback(overallScore, formScore, effortScore, consistencyScore);
  
  const result: JudgeOutput = {
    xp_multiplier: xpMultiplier,
    feedback,
    suggested_improvements: getSuggestedImprovements(overallScore),
    form_score: formScore,
    effort_score: effortScore,
    consistency_score: consistencyScore,
    overall_score: overallScore,
  };
  
  // Trace the evaluation
  opik.trace('ai_judge_evaluation', {
    userId: input.completion.user_id,
    questId: input.quest.id,
    formScore,
    effortScore,
    consistencyScore,
    overallScore,
    xpMultiplier,
    xpEarned: Math.floor(input.quest.xp_reward * xpMultiplier),
    feedback,
    timestamp: new Date().toISOString(),
  });
  
  return result;
}
```

#### Form Evaluation (Computer Vision Placeholder)
```typescript
async function evaluateForm(proofMedia?: ProofMedia): Promise<number> {
  if (!proofMedia) return 0.5; // No proof = average score
  
  // TODO: Integrate computer vision for form analysis
  // This would analyze the proof photo/video for:
  // - Exercise form quality
  // - Proper technique
  // - Range of motion
  // - Safety violations
  
  // For now, use simple heuristics
  const analysis = await analyzeProofMedia(proofMedia);
  return analysis.formQuality;
}
```

#### Consistency Evaluation
```typescript
function evaluateConsistency(history: UserProfile[], completion: QuestCompletion): number {
  if (history.length < 3) return 0.5; // Not enough data
  
  const recentQuests = history.slice(-10);
  const avgDuration = recentQuests.reduce((sum, q) => sum + q.duration, 0) / recentQuests.length;
  const avgEffort = recentQuests.reduce((sum, q) => sum + q.eort, 0) / recentQuests.length;
  
  const durationScore = normalizeScore(completion.duration, avgDuration);
  const effortScore = normalizeScore(completion.eort, avgEffort);
  
  return (durationScore + effortScore) / 2;
}
```
```

### 2. Opik Tracing Implementation (7-AI-Implementation/trace-implementation.md) - **WINS "Evaluation and Observability" (25%)**

**Must Include:**
```markdown
## Opik Tracing Strategy

### What We Trace (ALL AI Interactions)

#### 1. Quest Generation Traces
```typescript
opik.trace('quest_generation', {
  userId: user.id,
  userRank: user.rank,
  userClass: user.class,
  userEquipment: user.equipment,
  userGoals: user.goals,
  promptLength: prompt.length,
  modelUsed: 'llama-3.3-70b-versatile',
  temperature: 0.7,
  maxTokens: 1000,
  responseTime: responseTime,
  generatedQuestDifficulty: quest.difficulty,
  exerciseCount: quest.exercises.length,
  questDuration: quest.duration_minutes,
  xpReward: quest.xp_reward,
  success: true,
  timestamp: new Date().toISOString(),
});
```

#### 2. AI Judge Evaluation Traces
```typescript
opik.trace('ai_judge_evaluation', {
  userId: user.id,
  questId: quest.id,
  questDifficulty: quest.difficulty,
  formScore,
  effortScore,
  consistencyScore,
  overallScore,
  xpMultiplier,
  xpEarned,
  feedback,
  suggestedImprovements,
  proofAnalyzed: !!proofMedia,
  judgeTime: evaluationDuration,
  timestamp: new Date().toISOString(),
});
```

#### 3. Performance Monitoring
```typescript
// API Response Time Monitoring
opik.trace('api_performance', {
  endpoint: '/api/quests/generate',
  responseTime: responseTime,
  status: 'success',
  timestamp: new Date().toISOString(),
});

// Database Query Time Monitoring
opik.trace('db_query_performance', {
  query: 'SELECT * FROM quests WHERE user_id = $1',
  executionTime: queryTime,
  rowsReturned: rowCount,
  timestamp: new Date().toISOString(),
});
```

#### 4. Error Tracking
```typescript
try {
  const quest = await generateQuest(user);
} catch (error) {
  opik.trace('quest_generation_error', {
    userId: user.id,
    error: error.message,
    stack: error.stack,
    errorType: error.constructor.name,
    timestamp: new Date().toISOString(),
  });
  
  // Send to error tracking
  Sentry.captureException(error);
}
```

### How Opik Improves Our System

#### 1. Better AI Prompts
- We track which prompts work best
- Optimize prompt engineering based on success rates
- A/B test different prompt strategies

#### 2. Improved Judge Accuracy
- We track judge scores vs user satisfaction
- Adjust weight of factors based on feedback
- Identify bias in evaluation

#### 3. Performance Optimization
- We track slow API calls
- Identify bottlenecks in quest generation
- Optimize based on real usage data

#### 4. Error Detection
- We track error patterns
- Identify common failure modes
- Proactively fix before users report

#### 5. Goal Alignment
**Our Goal:** Improve quest quality and user satisfaction

**How Opik Helps:**
- Shows quest success rate
- Tracks judge accuracy
- Monitors user engagement
- All traces tagged with goals

**Evidence:**
```typescript
opik.trace('goal_alignment_check', {
  goal: 'improve_quest_quality',
  metric: 'quest_success_rate',
  value: successRate,
  period: 'last_7_days',
  target: 0.85, // 85% success rate
  actual: currentRate,
  alignment: currentRate >= target ? 'aligned' : 'needs_improvement',
});
```
```

### 3. Security Implementation (5-Security/) - **SHOWS TECHNICAL DEPTH**

**Must Include:**
```markdown
## Row-Level Security (RLS) Implementation

### Why RLS Matters for ASCEND
- Users must only see their own quests
- XP cannot be manipulated by others
- Proof uploads are private to user
- Leaderboard shows anonymized data

### Complete RLS Policy Set
```sql
-- Users can only see their own data
CREATE POLICY "users_select_own" ON users
FOR SELECT
USING (auth.uid() = id);

CREATE POLICY "users_update_own" ON users
FOR UPDATE
USING (auth.uid() = id)
WITH CHECK (
  xp <= (SELECT xp FROM user_limits WHERE id = id)
);

-- Quests: Users can only create/update own quests
CREATE POLICY "quests_insert_own" ON quests
FOR INSERT
WITH CHECK (auth.uid() = user_id);

CREATE POLICY "quests_select_own" ON quests
FOR SELECT
USING (
  auth.uid() = user_id
  OR -- Public quests for demo
  is_public = true
);

-- Match History: Users can only insert own completions
CREATE POLICY "match_history_insert_own" ON match_history
FOR INSERT
WITH CHECK (auth.uid() = user_id);

-- XP Manipulation Prevention
CREATE POLICY "match_history_update_prevent_xp_cheat" ON match_history
FOR UPDATE
USING (auth.uid() = user_id)
WITH CHECK (
  xp_earned <= (
    SELECT max_xp 
    FROM quests 
    WHERE id = quest_id
  )
);

-- Leaderboard: Everyone can see, but only anonymized data
CREATE POLICY "leaderboard_select_public" ON leaderboard
FOR SELECT
USING (true) -- Public access
WITH CHECK (
  true -- Read-only view
);
```

### Anti-Cheat Database Triggers
```sql
-- Flag suspicious completion times (completing too fast)
CREATE TRIGGER detect_fast_completions
AFTER INSERT ON match_history
FOR EACH ROW
EXECUTE FUNCTION flag_fast_completions();

CREATE FUNCTION flag_fast_completions() RETURNS TRIGGER AS $$
BEGIN
  -- Flag if completed in less than 30% of expected time
  IF NEW.completed_at < NEW.started_at + (NEW.expected_duration * 0.3) THEN
    INSERT INTO flagged_activities (user_id, reason, details)
    VALUES (
      NEW.user_id,
      'Suspicious completion time',
      format('Completed %s quest in %s minutes (expected: %s min)',
        NEW.quest_id,
        EXTRACT(EPOCH FROM (NEW.completed_at - NEW.started_at)) / 60,
        NEW.expected_duration
      )
    );
    
    -- Notify Opik
    INSERT INTO opik_alerts (user_id, type, severity, data)
    VALUES (NEW.user_id, 'cheat_suspicion', 'medium', jsonb_build_object(
      'reason' => 'Fast completion',
      'questId' => NEW.quest_id,
      'actualTime' => NEW.completed_at,
      'expectedTime' => NEW.started_at
    ));
  END IF;
  
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Flag impossible XP gains (xp > quest maximum)
CREATE TRIGGER prevent_impossible_xp
BEFORE INSERT OR UPDATE ON match_history
FOR EACH ROW
EXECUTE FUNCTION validate_xp_gain();

CREATE FUNCTION validate_xp_gain() RETURNS TRIGGER AS $$
BEGIN
  -- Check against quest difficulty limits
  IF NEW.xp_earned > (
    SELECT max_xp 
    FROM quest_limits 
    WHERE difficulty = (
      SELECT difficulty FROM quests WHERE id = NEW.quest_id
    )
  ) THEN
    -- Reject the update
    RAISE EXCEPTION 'invalid_xp_gain'
    USING MESSAGE = 'XP gain exceeds quest limits',
    HINT = 'Maximum XP for this quest difficulty is %s',
    DETAIL = format('Attempted: %s, Maximum: %s', NEW.xp_earned, max_xp);
  END IF;
  
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;
```

### Proof Upload Security
```typescript
// File validation
function validateProofFile(file: File): ValidationResult {
  const MAX_SIZE = 10 * 1024 * 1024; // 10MB
  const ALLOWED_TYPES = ['image/jpeg', 'image/png', 'image/webp', 'video/mp4', 'video/webm'];
  
  // 1. File size check
  if (file.size > MAX_SIZE) {
    return { valid: false, error: 'File too large (max 10MB)' };
  }
  
  // 2. File type check
  if (!ALLOWED_TYPES.includes(file.type)) {
    return { valid: false, error: 'Invalid file type' };
  }
  
  // 3. Virus scan (would integrate in production)
  // const scanResult = await scanForMalware(file);
  // if (!scanResult.clean) {
  //   return { valid: false, error: 'File contains malware' };
  // }
  
  // 4. Image/video validation
  if (file.type.startsWith('image/')) {
    const image = await validateImage(file);
    if (!image.valid) return image;
  }
  
  if (file.type.startsWith('video/')) {
    const video = await validateVideo(file);
    if (!video.valid) return video;
  }
  
  // Trace validation
  opik.trace('proof_validation', {
    userId: userId,
    fileSize: file.size,
    fileType: file.type,
    validationTime: Date.now(),
    result: 'valid',
  });
  
  return { valid: true };
}
```
```

### 4. Innovation Section (11-Innovation-and-Future-Roadmap.md) - **WINS "Real-World Relevance" (25%)**

**Must Include:**
```markdown
## Key Innovations

### 1. AI-Powered Quest Personalization
**Problem:** Generic workout apps don't adapt to users
**Our Solution:** Groq LLM generates unlimited quest variations
**Why It's Unique:**
- Every quest is personalized to user's:
  - Current rank (E-S)
  - Available equipment
  - Fitness goals
  - Class specialization (Tank/Striker/Assassin)
- Adapts over time based on:
  - Quest history
  - Performance trends
  - User feedback
- Unlike static workout plans, ours evolves with the user

**Evidence:**
- 40 unique demo accounts with different ranks
- Each generates personalized quests
- Quest variety based on equipment availability

### 2. AI Judge with Continuous Learning
**Problem:** No feedback on workout quality
**Our Solution:** Multi-factor evaluation with Opik tracking
**Why It's Unique:**
- Evaluates 3 factors: Form, Effort, Consistency
- Provides personalized feedback
- Tracks evaluation accuracy over time
- Adjusts scoring based on real data
- Opik traces provide transparency

**Evidence:**
- Judge logic documented in GitBook
- All evaluations traced to Opik
- Feedback loop for improvement

### 3. Anti-Cheat Verification System
**Problem:** Fitness apps can be easily cheated
**Our Solution:** Proof uploads + automated detection
**Why It's Unique:**
- Multi-layer verification:
  1. Proof upload requirement
  2. Time anomaly detection (database triggers)
  3. XP limit enforcement
  4. Community reporting system
- Database triggers for real-time flagging
- RLS policies prevent data manipulation
- Opik alerts for suspicious activity

**Evidence:**
- Complete RLS policy documentation
- Anti-cheat triggers implemented
- Community report system functional

### 4. Social Hunter Network
**Problem:** Fitness is lonely, lacks community
**Our Solution:** Strava-inspired social feed
**Why It's Unique:**
- Gamified social interactions (kudos, respects)
- Quest sharing and celebration
- Real-time leaderboard
- Hunter status verification system
- Different ranks unlock different social features

**Evidence:**
- Hunter Network feed implemented
- Social feed cards with kudos/respects
- Leaderboard with real-time updates

### 5. Transparent AI Monitoring with Opik
**Problem:** Users don't trust black-box AI
**Our Solution:** Full transparency via Opik integration
**Why It's Unique:**
- Shows exactly what's tracked
- Documents what's NOT tracked (workout data privacy)
- Provides user rights (know, control, access, deletion)
- Uses traces to improve system quality
- Goal alignment clearly demonstrated

**Evidence:**
- Opik documentation in `/help/opik`
- All AI interactions traced
- Privacy-first approach
```

---

## ‚è∞ IMPLEMENTATION TIMELINE (5 Hours Total)

### Hour 1: GitBook Setup + Core Structure
- [ ] Create GitBook account/space
- [ ] Initialize GitBook repository
- [ ] Set up custom domain (if available)
- [ ] Create README.md (landing page)
- [ ] Create 1-Getting-Started/quick-start.md
- [ ] Create 1-Getting-Started/installation.md

### Hour 2: Architecture + Database
- [ ] Create 2-Architecture/system-overview.md
- [ ] Create 2-Architecture/frontend-architecture.md
- [ ] Create 2-Architecture/backend-architecture.md
- [ ] Create 2-Architecture/ai-integration.md (**CRITICAL**)
- [ ] Create 3-Database/schema.md
- [ ] Create 3-Database/relationships.md

### Hour 3: Features + AI Implementation (**MAXIMUM POINTS**)
- [ ] Create 4-Features/quest-system.md
- [ ] Create 4-Features/ai-judge.md (**WINNING POINT**)
- [ ] Create 4-Features/gamification.md
- [ ] Create 7-AI-Implementation/groq-quest-generation.md
- [ ] Create 7-AI-Implementation/opik-ai-judge.md (**WINNING POINT**)
- [ ] Create 7-AI-Implementation/trace-implementation.md (**EXTRA POINTS**)

### Hour 4: Security + Performance + Testing
- [ ] Create 5-Security/rls-implementation.md
- [ ] Create 5-Security/api-security.md
- [ ] Create 6-Performance/frontend-optimization.md
- [ ] Create 6-Performance/opik-monitoring.md (**EXTRA POINTS**)
- [ ] Create 8-Testing/unit-testing.md
- [ ] Create 8-Testing/integration-testing.md

### Hour 5: Innovation + Final Polish
- [ ] Create 11-Innovation-and-Future-Roadmap.md (**WINNING POINT**)
- [ ] Create 9-Deployment/vercel-setup.md
- [ ] Create 10-Code-Examples/server-actions.md
- [ ] Add diagrams/architecture visuals
- [ ] Add code syntax highlighting
- [ ] Proofread all sections
- [ ] Test all links work

---

## üéØ SUCCESS CRITERIA

### For "Evaluation and Observability" (25%) - MUST HAVE
- [ ] Opik SDK integration documented
- [ ] All AI interactions traced
- [ ] Performance metrics tracked
- [ ] Error tracking implemented
- [ ] Goal alignment explained
- [ ] Opik dashboards/screenshots included

### For "Use of LLMs/Agents" (25%) - MUST HAVE
- [ ] Groq LLM usage documented
- [ ] Prompt engineering examples shown
- [ ] Response parsing/validation explained
- [ ] AI judge logic detailed
- [ ] Multi-factor evaluation documented
- [ ] Fallback strategy explained

### For "Functionality" (25%) - MUST HAVE
- [ ] Complete feature list
- [ ] Architecture diagrams
- [ ] Database schema documentation
- [ ] API endpoints documented
- [ ] Code examples provided

### For "Real-World Relevance" (25%) - BONUS POINTS
- [ ] Problem statement explained
- [ ] Solution clearly connects to fitness
- [ ] User testimonials/demo
- [ ] Innovation highlighted
- [ ] Future roadmap included

---

## üìä BONUS POINTS STRATEGY

### Maximum Bonus Points for Best Use of Opik ($5,000)

**Must Demonstrate:**
1. **Comprehensive Tracing** - All AI operations traced
2. **Goal Alignment** - Clear connection to improving quest quality
3. **Visualization** - Opik dashboards/screenshots
4. **Transparency** - What we track/don't track
5. **Iterative Improvement** - How Opik data drives better decisions

**Evidence in GitBook:**
- 7-AI-Implementation/opik-ai-judge.md (judge logic)
- 7-AI-Implementation/trace-implementation.md (all traces)
- 6-Performance/opik-monitoring.md (performance metrics)
- 11-Innovation-and-Future-Roadmap.md (future improvements)

### Documentation Quality Bonus Points

**To Maximize:**
1. Searchable structure (GitBook search)
2. Code examples with syntax highlighting
3. Architecture diagrams (Mermaid/Draw.io)
4. Step-by-step tutorials
5. Troubleshooting guides
6. Performance metrics/benchmarks
7. Security best practices
8. Testing strategies

---

## üöÄ READY TO EXECUTE

This plan is optimized for:
- ‚úÖ **Maximum hackathon points** (4 prize categories)
- ‚úÖ **Best Use of Opik** (comprehensive traces)
- ‚úÖ **Technical depth** (shows we understand our stack)
- ‚úÖ **Real-world relevance** (solves actual fitness problems)
- ‚úÖ **Innovation** (unique AI + gamification approach)

**Time Required:** 5 hours focused execution

**Expected Outcome:**
- Comprehensive GitBook with 11 sections
- Clear path to 5 prize categories
- Maximum "Evaluation and Observability" points
- Maximum "Use of LLMs/Agents" points
- Professional documentation that impresses judges

---

**Plan Created:** Feb 5, 2026
**For Execution:** PROMPT_MASTER.md in this directory
